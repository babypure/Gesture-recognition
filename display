import h5py 
import numpy as np
import scipy.io as sio
from scipy.signal import butter, lfilter, hilbert
import matplotlib.pyplot as plt

matFilePath = r"../Gesture recognition/1st/1.mat"

with h5py.File(matFilePath, 'r') as f:
    RcvData = f['RcvData']
    ref_0_0 = RcvData[0, 0]
    dataset_0_0 = f[ref_0_0]
    print("Original shape in Python:", dataset_0_0.shape)
    data_np = dataset_0_0[()]
    data_np = np.transpose(data_np, (2, 1, 0))
print("After transpose, shape:", data_np.shape)

signal_0 = data_np[:, :16, :].astype(float)  # shape = (1152, 16, 3000)

num_trimmed = 1024
num_channels = 16
num_trials = 1000
signal = np.zeros((num_trimmed, num_channels, num_trials), dtype=float)

signal_0_length = signal_0.shape[0]

for j in range(num_channels):
    for k in range(num_trials):
        start = min(1664 * j + 80, signal_0_length - num_trimmed)
        end = start + num_trimmed
        signal[:, j, k] = signal_0[start:end, j, k]

print("Final trimmed signal shape:", signal.shape)

mat1 = sio.loadmat(r"../Gesture recognition/202502_10s_10gesture_1_8_1_3/250217_1_8_1_3_Receive.mat")
Receive = mat1['Receive']
fs_val = Receive['decimSampleRate'][0, 0]
fs = float(fs_val) * 1e6
print("Loaded sample rate fs =", fs)

center_freq = 7.8125e6 
bw = 0.3 * center_freq
f_low = center_freq - bw / 2
f_high = center_freq + bw / 2

if f_high >= fs / 2:
    raise ValueError("exceed (fs/2)")

order = 8
b, a = butter(order, [f_low, f_high], btype='band', fs=fs)
print("Designed bandpass filter with f_low =", f_low, "and f_high =", f_high)

filtered_signal = np.zeros_like(signal)
num_samples, num_channels, num_trials = signal.shape
for ch in range(num_channels):
    for tr in range(num_trials):
        filtered_signal[:, ch, tr] = lfilter(b, a, signal[:, ch, tr])

filtered_segment = filtered_signal[:, 0, 0]
envelope_segment = np.abs(hilbert(filtered_segment))

original_full = signal_0[:1664, 0, 0]
start_index = min(1664 * 0 + 80, signal_0_length - num_trimmed)
end_index = start_index + num_trimmed
trimmed_segment = signal[:, 0, 0]

plt.figure(figsize=(12, 16))

# Original
plt.subplot(4, 1, 1)
plt.plot(original_full, color='#0070C0', label='Original signal')
plt.axvline(x=80, color='black', linestyle='--', label='Boundary at 80')
boundary2 = len(original_full) - 48
plt.axvline(x=boundary2, color='black', linestyle='--', label=f'Boundary at {boundary2}')
plt.title('Original signal with dashed separators')
plt.xlabel('Sample index')
plt.ylabel('Value')
plt.legend()

plt.subplot(4, 1, 2)
plt.plot(trimmed_segment, color='#0070C0')
plt.title('Trimmed signal')
plt.xlabel('Sample index')
plt.ylabel('Value')

plt.subplot(4, 1, 3)
plt.plot(filtered_segment, color='#0070C0')
plt.title('Filtered signal')
plt.xlabel('Sample index')
plt.ylabel('Value')

plt.subplot(4, 1, 4)
plt.plot(envelope_segment, color='#0070C0')
plt.title('Envelope signal')
plt.xlabel('Sample index')
plt.ylabel('Value')

plt.tight_layout()
plt.savefig(
    r"../Gesture recognition/plot_marked.svg",
    format="svg", dpi=600, bbox_inches='tight'
)
plt.show()

np.savetxt(
    r"../Gesture recognition/original_full.csv",
    original_full, delimiter=","
)
np.savetxt(
    r"../Gesture recognition/trimmed_segment.csv",
    trimmed_segment, delimiter=","
)
np.savetxt(
    r"../Gesture recognition/filtered_segment.csv",
    filtered_segment, delimiter=","
)
np.savetxt(
    r"../Gesture recognition/envelope_segment.csv",
    envelope_segment, delimiter=","
)
